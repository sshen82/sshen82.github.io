---
layout: post
title: Summary and Comment on "Statistical Modeling The Two Cultures"
gh-repo: daattali/beautiful-jekyll
tags: [BMI881]
comments: true
---

This paper discusses two different approaches toward prediction and interpretation: The data modeling culture, and the algorithmic modeling culture. The data modeling culture 
assumes a data generating process (a stochastic data model) inside the black box, and uses statistical testing to assess the goodness-of-fit, etc.. The algorithmic modeling 
culture considers the black box unknown, and it fits a function that better predict the response. The author uses examples to point out that the statistical field at that time
failed to follow what the industry has done, and only focused on "useless" theories. 

The first point is that this paper is great, but outdated. Currently, almost all papers in journals like JASA will consist a data application part. (I don't read Annal of 
Statistics so don't know much about that), and statisticans are communicating more with the industry. Also, statistical and computational theory for both machine learning and 
statistical methods are investigated. For example, for regularized regression, both PAC-bound and asymptotic properties are quite thoroughly studied.

Secondly, the author seems to be focusing too much on prediction. However, I feel that currently, researchers focus both on prediction and interpretation. For example, we can 
classify breast cancer very correctly using huge neural networks, but I don't see doctors using this. Afterall, there might be ethical issues simply by using an algorithm. Like 
Prof. Efron said in the comment, "prediction by itself is only occasionally sufficient." Because of this, nowadays, those methods are also focusing much on interpretability. In
genomics, methods like scVI combines statistical model with neural networks by assuming that the data follows zero-inflated Negative Binomial, but the parameters in the model
are fitted via neural networks. In computer science, people also try to interpret the output of the neural networks by various methods.

Finally, I feel that those data modeling can also handle non-linearity, but this part is what I am not familiar with. Do people use for example, generative additive model to 
both do inference and do prediction? I think that this kind of method can provide both of them.
