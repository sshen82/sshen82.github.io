---
layout: post
title: Summary and Comment on "Controlling the False Discovery Rate A Practical and Powerful Approach to Multiple Testing"
gh-repo: daattali/beautiful-jekyll
tags: [BMI881]
comments: true
---

In this paper, the authors proposed a new approach to multiple testing. Instead of controlling the familywise error rate (FWER), they control
the false discovery rate (FDR). By using this, they are able to face the situation with different statistics, statistics with different distributions than Normal, 
and gain statistical power. The definition of FDR is the expected value of the proportion of the rejected null hypothesis which are erroneously rejected. 
FWER is defined as the probability to have even one falsely rejected the null hypothesis. The two are equivalent when all null hypotheses are true; otherwise, 
FDR is smaller.

In real data study in genomics, I think one thing we do often is to gather all the genes significant and look at their overall pattern. In this case, even if the 
method we use is not conservative, the overall pattern can be shown. We also have some initial hypothesis. For example, in the collaboration I am working on, the
collaborator cares about a set of specific genes, and when these genes are significant (or even just nearly significant), it is an assurance of their hypothesis.
In other cases, it might not be as "easy" as what I am doing. 

The second point I wish to discuss is that is there a "better" method among all those adjustment methods? The p.adjust function contains at least 6 methods if I 
remember correctly. I normally use BH or Bonferroni simply because they are used more often (as far as I know).

The third point is that for all those biological studies, it will be like p-hacking when we try all methods and pick the one that is in favor of us. What I wish to 
say is that it is more important when the significant genes (or drugs) make sense biologically, and can be confirmed by other studies or other experiments. 
